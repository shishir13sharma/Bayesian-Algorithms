{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "from numpy.linalg import eig\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.datasets import make_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_tuple():\n",
    "    \n",
    "    def __init__(self, data, K):\n",
    "        self.length = data.shape[0]\n",
    "        self.X = data    \n",
    "        self.Z = np.random.randint(K, size=self.length)\n",
    "\n",
    "clr = ['r','b', 'k', 'g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cov_ellipse(cov, centre, nstd, clr):\n",
    "\n",
    "    eigvals, eigvecs = eig(cov)\n",
    "    order = eigvals.argsort()[::-1]\n",
    "    eigvals, eigvecs = eigvals[order], eigvecs[:, order]\n",
    "\n",
    "    vx, vy = eigvecs[:,0][0], eigvecs[:,0][1]\n",
    "    theta = np.arctan2(vy, vx)    \n",
    "\n",
    "    width, height = 2 * nstd * np.sqrt(eigvals)\n",
    "    ellipse = Ellipse(xy=centre, width=width, height=height, angle=np.degrees(theta), color=clr,\n",
    "                      fill = True,alpha=0.4)    \n",
    "    return ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gaussianpdf():\n",
    "    \n",
    "    def __init__(self, mean, covar):\n",
    "        self.mean = mean\n",
    "        self.covar = covar\n",
    "        \n",
    "    def pdf(self, X):\n",
    "                \n",
    "        D = 2         \n",
    "        exp_arg = -0.5*np.matmul(np.matmul(X - self.mean, inv(self.covar)),np.transpose(X - self.mean))        \n",
    "        const = 1.0/((2*np.pi)**(D/2.0) * det(self.covar)**0.5)        \n",
    "        return np.squeeze(const*np.exp(exp_arg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EM():\n",
    "        \n",
    "    def __init__(self, K, D, data):\n",
    "\n",
    "        mu = np.random.rand(K, 2)\n",
    "        Z = data.Z\n",
    "        X = data.X\n",
    "\n",
    "        self.means = mu\n",
    "        self.covar = [np.cov(np.transpose(X[Z[:,j] == 1])) for j in range(K)]\n",
    "        self.models = [Gaussianpdf(self.means[j], self.covar[j]) for j in range(K)]\n",
    "        self.pi = np.sum(Z, axis=0)/data.length                    \n",
    "        self.K = K\n",
    "        self.D = D\n",
    "    \n",
    "    def E_step(self, data):\n",
    "        \n",
    "        p_z_given_x = np.zeros((data.length, self.K))\n",
    "        X = data.X\n",
    "        Z = data.Z        \n",
    "        mu = [self.models[j].mean for j in range(self.K)]\n",
    "        covar = [self.models[j].covar for j in range(self.K)]\n",
    "        pi = self.pi\n",
    "        \n",
    "        for i in range(data.length):\n",
    "            \n",
    "            for j in range(self.K):                \n",
    "                p_z_given_x[i,j] = pi[j] * self.models[j].pdf(X[i])\n",
    "            \n",
    "            p_z_given_x[i,:] = p_z_given_x[i,:]/np.sum(p_z_given_x[i,:])\n",
    "                    \n",
    "        self.p_z_given_x = p_z_given_x       \n",
    "    \n",
    "    def M_step(self, data):\n",
    "        \n",
    "        X = data.X\n",
    "        Z = data.Z\n",
    "        D = self.D\n",
    "        mu = [self.models[j].mean for j in range(self.K)]\n",
    "        covar = [self.models[j].covar for j in range(self.K)]\n",
    "        pi = self.pi\n",
    "        p_z_given_x = self.p_z_given_x\n",
    "        \n",
    "        self.pi = np.sum(p_z_given_x, axis=0)/data.length        \n",
    "        \n",
    "        for j in range(self.K):           \n",
    "            \n",
    "            self.models[j].covar = np.zeros((D, D))\n",
    "            self.models[j].mean = 0\n",
    "            for i in range(data.length):\n",
    "                \n",
    "                self.models[j].mean = self.models[j].mean + p_z_given_x[i,j]*X[i]\n",
    "                self.models[j].covar = self.models[j].covar + p_z_given_x[i,j]*np.matmul((X[i] - mu[j])[:,np.newaxis],\n",
    "                                                                                         (X[i] - mu[j])[np.newaxis,:])            \n",
    "            self.models[j].mean = self.models[j].mean/np.sum(p_z_given_x[:,j]) \n",
    "            self.models[j].covar = self.models[j].covar/np.sum(p_z_given_x[:,j])        \n",
    "            \n",
    "    def run_em(self, data):\n",
    "            \n",
    "        Zold = data.Z            \n",
    "        while True:                    \n",
    "\n",
    "            self.E_step(data)\n",
    "            self.M_step(data)\n",
    "            \n",
    "            Znew = np.argmax(self.p_z_given_x, axis=1)\n",
    "\n",
    "            if np.array_equal(Zold,Znew):\n",
    "                break\n",
    "\n",
    "            Zold = Znew   \n",
    "\n",
    "    def log_likelihood(self, data):\n",
    "        \n",
    "        X = data.X\n",
    "        Z = data.Z\n",
    "        D = self.D\n",
    "        mu = [self.models[j].mean for j in range(self.K)]        \n",
    "        pi = self.pi\n",
    "        self.sigma2 = np.zeros(K)\n",
    "        p_z_given_x = self.p_z_given_x\n",
    "        ll = 0\n",
    "        \n",
    "        for i in range(data.length):\n",
    "            for j in range(self.K):\n",
    "                ll = ll + p_z_given_x[i,j]*np.log(self.pi[j])\n",
    "                ll = ll + p_z_given_x[i,j]*np.log(self.models[j].pdf(X[i]))\n",
    "        \n",
    "        return ll*1.0/data.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating Data from different gaussian distributions\n",
    "\n",
    "K = 4\n",
    "means = np.array([[1.1, 1.7], [-5.7, 1.4],[8.7, -3.9], [8.5, 6.6]])\n",
    "covar = 2*np.array([make_spd_matrix(2) for i in range(K)])\n",
    "\n",
    "data = np.array([np.random.multivariate_normal(means[i], covar[i], size=100) for i in range(K)])\n",
    "data = np.reshape(data, [K*100, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "D = data.shape[1]\n",
    "complete_data = Data_tuple(data, K)  # Latent Variable initialized randomly        \n",
    "\n",
    "# One hot Encoding\n",
    "Z = np.zeros((complete_data.length, K))\n",
    "Z[np.arange(complete_data.length), complete_data.Z] = 1\n",
    "complete_data.Z = Z\n",
    "\n",
    "em_gen = EM(K, D, complete_data)\n",
    "em_gen.run_em(complete_data)\n",
    "\n",
    "complete_data.Z = np.argmax(em_gen.p_z_given_x,axis=1)    \n",
    "\n",
    "# fig = plt.figure(figsize=(10,5))\n",
    "# plt.xlabel('X1')\n",
    "# plt.ylabel('X2')\n",
    "# for i in range(complete_data.length):\n",
    "#     plt.plot(complete_data.X[i,0], complete_data.X[i,1],clr[complete_data.Z[i]] + '.')\n",
    "# for k in range(K):\n",
    "#     plt.plot(em_gen.models[k].mean[0], em_gen.models[k].mean[1], clr[k] + '^', markersize=12,\n",
    "#             markeredgecolor='k')   \n",
    "#     ellipse = get_cov_ellipse(em_gen.models[k].covar, em_gen.models[k].mean, 1.645, clr[k])          \n",
    "#     ax = fig.axes[0]\n",
    "#     ax.add_patch(ellipse)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood: -5.160688074851878\n"
     ]
    }
   ],
   "source": [
    "print(\"Log Likelihood: \" + str(em_gen.log_likelihood(complete_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![em](gif/em2.gif \"Expectation Maximization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
